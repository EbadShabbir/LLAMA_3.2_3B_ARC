{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install dependencies\n!pip install transformers datasets torch nltk rouge_score psutil gpustat\n\n# Set environment variable to reduce memory fragmentation\nimport os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n\n# Hugging Face login\nfrom huggingface_hub import login\nlogin(\"HUGGING FACE TOKEN\")  # Replace with your actual Hugging Face token\n\nimport time\nimport torch\nimport psutil\nimport gpustat\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom datasets import load_dataset\nfrom nltk.translate.bleu_score import sentence_bleu\nfrom rouge_score import rouge_scorer\nimport numpy as np\nfrom tqdm import tqdm\n\n# Load model and tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B\")\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"meta-llama/Llama-3.2-3B\",\n    device_map=\"auto\",  # Use \"0\" for single GPU if OOM persists\n    torch_dtype=torch.float16\n)\nmodel.eval()\n\n# Load ARC-Challenge dataset (first 500 samples from test split)\ndataset = load_dataset(\"allenai/ai2_arc\", \"ARC-Challenge\", split=\"test[:500]\")\n\n# Initialize metrics\nlatencies, tokens_per_sec, perplexities, bleus, rouge1s, rougeLs, memories, f1s = [], [], [], [], [], [], [], []\nscorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n\n# Evaluation loop\nfor sample in tqdm(dataset, desc=\"Evaluating\"):\n    question = sample[\"question\"]\n    choices = sample[\"choices\"][\"text\"]\n    answer_key = sample[\"answerKey\"]  # Typically A, B, C, D, or a number\n    # Map answerKey to the corresponding choice text\n    answer_idx = ord(answer_key) - ord('A') if answer_key in 'ABCD' else int(answer_key) - 1\n    reference = choices[answer_idx].strip()\n\n    # Create prompt for multiple-choice question\n    choices_text = \"\\n\".join([f\"{chr(65+i)}. {choice}\" for i, choice in enumerate(choices)])\n    prompt = f\"Answer the following question by selecting the correct choice (A, B, C, D, or number):\\n{question}\\n{choices_text}\\nProvide the final answer as the choice letter (A, B, C, D) or number.\"\n\n    # Tokenize input\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n    input_length = inputs.input_ids.size(1)\n\n    # Clear GPU memory\n    torch.cuda.empty_cache()\n\n    # Measure latency and generate\n    start_time = time.time()\n    with torch.no_grad():\n        outputs = model.generate(\n            **inputs,\n            max_new_tokens=20,  # Reduced to minimize memory\n            do_sample=False\n        )\n    latency = time.time() - start_time\n\n    # Decode output\n    generated = tokenizer.decode(outputs[0][input_length:], skip_special_tokens=True).strip()\n    output_length = outputs[0][input_length:].size(0)\n\n    # Latency and tokens per second\n    latencies.append(latency)\n    tokens_per_sec.append(output_length / latency if latency > 0 else 0)\n\n    # Perplexity (forward pass, skip for very short sequences)\n    if output_length > 2:\n        with torch.no_grad():\n            input_ids = outputs[:, input_length:].to(\"cuda\")\n            labels = input_ids.clone().to(\"cuda\")\n            outputs_forward = model(input_ids, labels=labels)\n            perplexity = torch.exp(outputs_forward.loss).item()\n        perplexities.append(perplexity)\n    else:\n        perplexities.append(float('inf'))\n\n    # BLEU and ROUGE\n    bleu = sentence_bleu([reference.split()], generated.split())\n    bleus.append(bleu)\n    rouge_scores = scorer.score(reference, generated)\n    rouge1s.append(rouge_scores['rouge1'].fmeasure)\n    rougeLs.append(rouge_scores['rougeL'].fmeasure)\n\n    # Memory usage (GPU)\n    gpu_stats = gpustat.new_query().gpus[0]\n    memory_used = gpu_stats.memory_used / 1024  # Convert MB to GB\n    memories.append(memory_used)\n\n    # F1 Score (binary: correct or not)\n    # Compare generated answer (e.g., 'A') with reference choice text\n    is_correct = generated == answer_key\n    f1 = 1.0 if is_correct else 0.0\n    f1s.append(f1)\n\n    # Log memory usage for debugging\n    print(f\"Sample {len(latencies)}: GPU Memory Used: {memory_used:.3f} GB\")\n\n# Compute averages\navg_latency = np.mean(latencies)\navg_tps = np.mean(tokens_per_sec)\navg_perplexity = np.mean([p for p in perplexities if p != float('inf')]) if perplexities else float('inf')\navg_bleu = np.mean(bleus)\navg_rouge1 = np.mean(rouge1s)\navg_rougeL = np.mean(rougeLs)\navg_memory = np.mean(memories)\navg_f1 = np.mean(f1s)\navg_knowledge_retention = avg_f1\navg_flop_reduction = 0.0\navg_retrieval_latency = 0.0\navg_memory_reduction = 0.0\navg_query_time = avg_latency\navg_accuracy_drop = 0.0\navg_compression_ratio = 1.0\n\n# Print results\nprint(f\"Avg latency: {avg_latency:.3f} sec\")\nprint(f\"Tokens per sec: {avg_tps:.2f}\")\nprint(f\"Avg perplexity: {avg_perplexity:.2f}\")\nprint(f\"BLEU Score: {avg_bleu:.3f}\")\nprint(f\"ROUGE-1 Score: {avg_rouge1:.3f}\")\nprint(f\"ROUGE-L Score: {avg_rougeL:.3f}\")\nprint(f\"Memory usage (GB): {avg_memory:.3f}\")\nprint(f\"FLOP Reduction (%): {avg_flop_reduction:.2f}\")\nprint(f\"Retrieval Latency (sec): {avg_retrieval_latency:.3f}\")\nprint(f\"F1 Score: {avg_f1:.3f}\")\nprint(f\"Knowledge Retention: {avg_knowledge_retention:.3f}\")\nprint(f\"Memory Reduction (%): {avg_memory_reduction:.2f}\")\nprint(f\"Query Processing Time (sec): {avg_query_time:.3f}\")\nprint(f\"Accuracy Drop: {avg_accuracy_drop:.3f}\")\nprint(f\"Compression Ratio: {avg_compression_ratio:.2f}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:56:32.830454Z","iopub.execute_input":"2025-04-21T18:56:32.830683Z","iopub.status.idle":"2025-04-21T19:01:20.044605Z","shell.execute_reply.started":"2025-04-21T18:56:32.830666Z","shell.execute_reply":"2025-04-21T19:01:20.043935Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (7.0.0)\nCollecting gpustat\n  Downloading gpustat-1.1.1.tar.gz (98 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: nvidia-ml-py>=11.450.129 in /usr/local/lib/python3.11/dist-packages (from gpustat) (12.570.86)\nCollecting blessed>=1.17.1 (from gpustat)\n  Downloading blessed-1.20.0-py2.py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.11/dist-packages (from blessed>=1.17.1->gpustat) (0.2.13)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge_score, gpustat\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=50ad4cf5bd25e1647c51a228a581927b0d619d3f7a32093cc55d55a59153533e\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n  Building wheel for gpustat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for gpustat: filename=gpustat-1.1.1-py3-none-any.whl size=26666 sha256=23ecb1a30670eb18652fca6023474e0406d190423e107e4c4274ba617f4a4de0\n  Stored in directory: /root/.cache/pip/wheels/c9/2b/d9/a0b77d6e8623ce6b5c73813af455a3ace394abfc2e8aef7ed6\nSuccessfully built rouge_score gpustat\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, blessed, nvidia-cusparse-cu12, nvidia-cudnn-cu12, gpustat, nvidia-cusolver-cu12, rouge_score\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed blessed-1.20.0 fsspec-2024.12.0 gpustat-1.1.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 rouge_score-0.1.2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60bec47b783242769920e059290a25cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce28ad93fd5046dfb4d4c3ad9d55e0a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ecc6828fa61439696f0e0bdedb1d565"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/844 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1144a18f08d84983aa3a0487a97077ad"}},"metadata":{}},{"name":"stderr","text":"2025-04-21 18:58:12.360286: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745261892.563956      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745261892.619569      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c641a4db9af0402e9d155b5266568b12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b90645a4e2e4aabbddd256d5b0a83ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2695477a0d842f6a6e0e85c376a279e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91563bfe6fbc4b64bc8e6f39110a156d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67cd8584b1ee4f298da440de50d87bc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e70a93ef06d41eaab78e36d74c77aa9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/9.00k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd0f6f9cdcf2403588d6f47c0e2704f9"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/190k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dae2207b9c6c4e5bb55d0855e5f64b02"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/204k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1114ab8f41e247c2ae4308c3faefa540"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/55.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e37b7bd4729c4ca3814dfe8bbcb7453d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1119 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05c7254fd1f642d1b1a03f5aed8d1b9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1172 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cfa693fac724a7cb77de34f97f3323c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/299 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bdc53bc7a334fef8838e20b9f855c0a"}},"metadata":{}},{"name":"stderr","text":"Evaluating:   0%|          | 0/500 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nEvaluating:   0%|          | 1/500 [00:00<08:01,  1.04it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 1: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   0%|          | 2/500 [00:01<04:42,  1.76it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 2: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   1%|          | 3/500 [00:01<03:39,  2.27it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 3: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   1%|          | 4/500 [00:01<03:09,  2.62it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 4: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   1%|          | 5/500 [00:02<02:55,  2.82it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 5: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   1%|          | 6/500 [00:02<02:47,  2.95it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 6: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   1%|▏         | 7/500 [00:02<02:42,  3.03it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 7: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   2%|▏         | 8/500 [00:03<02:36,  3.15it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 8: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   2%|▏         | 9/500 [00:03<02:34,  3.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 9: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   2%|▏         | 10/500 [00:03<02:30,  3.27it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 10: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   2%|▏         | 11/500 [00:03<02:27,  3.32it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 11: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   2%|▏         | 12/500 [00:04<02:24,  3.37it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 12: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   3%|▎         | 13/500 [00:04<02:22,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 13: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   3%|▎         | 14/500 [00:04<02:22,  3.42it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 14: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   3%|▎         | 15/500 [00:05<02:21,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 15: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   3%|▎         | 16/500 [00:05<02:20,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 16: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   3%|▎         | 17/500 [00:05<02:22,  3.38it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 17: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   4%|▎         | 18/500 [00:05<02:21,  3.40it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 18: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   4%|▍         | 19/500 [00:06<02:23,  3.34it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 19: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   4%|▍         | 20/500 [00:06<02:22,  3.37it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 20: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   4%|▍         | 21/500 [00:06<02:20,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 21: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   4%|▍         | 22/500 [00:07<02:22,  3.35it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 22: GPU Memory Used: 3.152 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   5%|▍         | 23/500 [00:07<02:20,  3.39it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 23: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   5%|▍         | 24/500 [00:07<02:22,  3.35it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 24: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   5%|▌         | 25/500 [00:08<02:19,  3.40it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 25: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   5%|▌         | 26/500 [00:08<02:18,  3.42it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 26: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   5%|▌         | 27/500 [00:08<02:17,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 27: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   6%|▌         | 28/500 [00:08<02:19,  3.38it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 28: GPU Memory Used: 3.152 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   6%|▌         | 29/500 [00:09<02:18,  3.40it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 29: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   6%|▌         | 30/500 [00:09<02:16,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 30: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   6%|▌         | 31/500 [00:09<02:16,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 31: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   6%|▋         | 32/500 [00:10<02:15,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 32: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   7%|▋         | 33/500 [00:10<02:14,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 33: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   7%|▋         | 34/500 [00:10<02:13,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 34: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   7%|▋         | 35/500 [00:10<02:12,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 35: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   7%|▋         | 36/500 [00:11<02:13,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 36: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   7%|▋         | 37/500 [00:11<02:13,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 37: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   8%|▊         | 38/500 [00:11<02:12,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 38: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   8%|▊         | 39/500 [00:12<02:12,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 39: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   8%|▊         | 40/500 [00:12<02:12,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 40: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   8%|▊         | 41/500 [00:12<02:12,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 41: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   8%|▊         | 42/500 [00:12<02:11,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 42: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   9%|▊         | 43/500 [00:13<02:11,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 43: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   9%|▉         | 44/500 [00:13<02:11,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 44: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   9%|▉         | 45/500 [00:13<02:10,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 45: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   9%|▉         | 46/500 [00:14<02:09,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 46: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   9%|▉         | 47/500 [00:14<02:09,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 47: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  10%|▉         | 48/500 [00:14<02:08,  3.51it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 48: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  10%|▉         | 49/500 [00:14<02:08,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 49: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  10%|█         | 50/500 [00:15<02:08,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 50: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  10%|█         | 51/500 [00:15<02:11,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 51: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  10%|█         | 52/500 [00:15<02:10,  3.42it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 52: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  11%|█         | 53/500 [00:16<02:09,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 53: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  11%|█         | 54/500 [00:16<02:08,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 54: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  11%|█         | 55/500 [00:16<02:08,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 55: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  11%|█         | 56/500 [00:17<02:10,  3.39it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 56: GPU Memory Used: 3.152 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  11%|█▏        | 57/500 [00:17<02:10,  3.40it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 57: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  12%|█▏        | 58/500 [00:17<02:09,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 58: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  12%|█▏        | 59/500 [00:17<02:07,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 59: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  12%|█▏        | 60/500 [00:18<02:10,  3.38it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 60: GPU Memory Used: 3.152 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  12%|█▏        | 61/500 [00:18<02:08,  3.42it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 61: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  12%|█▏        | 62/500 [00:18<02:07,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 62: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  13%|█▎        | 63/500 [00:19<02:06,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 63: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  13%|█▎        | 64/500 [00:19<02:05,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 64: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  13%|█▎        | 65/500 [00:19<02:07,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 65: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  13%|█▎        | 66/500 [00:19<02:06,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 66: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  13%|█▎        | 67/500 [00:20<02:05,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 67: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  14%|█▎        | 68/500 [00:20<02:05,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 68: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  14%|█▍        | 69/500 [00:20<02:04,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 69: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  14%|█▍        | 70/500 [00:21<02:03,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 70: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  14%|█▍        | 71/500 [00:21<02:03,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 71: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  14%|█▍        | 72/500 [00:21<02:02,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 72: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  15%|█▍        | 73/500 [00:21<02:02,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 73: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  15%|█▍        | 74/500 [00:22<02:01,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 74: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  15%|█▌        | 75/500 [00:22<02:01,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 75: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  15%|█▌        | 76/500 [00:22<02:01,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 76: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  15%|█▌        | 77/500 [00:23<02:03,  3.42it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 77: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  16%|█▌        | 78/500 [00:23<02:03,  3.42it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 78: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  16%|█▌        | 79/500 [00:23<02:02,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 79: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  16%|█▌        | 80/500 [00:23<02:01,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 80: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  16%|█▌        | 81/500 [00:24<02:01,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 81: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  16%|█▋        | 82/500 [00:24<02:00,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 82: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  17%|█▋        | 83/500 [00:24<01:59,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 83: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  17%|█▋        | 84/500 [00:25<01:59,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 84: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  17%|█▋        | 85/500 [00:25<02:01,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 85: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  17%|█▋        | 86/500 [00:25<02:00,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 86: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  17%|█▋        | 87/500 [00:25<02:02,  3.38it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 87: GPU Memory Used: 3.152 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  18%|█▊        | 88/500 [00:26<02:03,  3.33it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 88: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  18%|█▊        | 89/500 [00:26<02:02,  3.35it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 89: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  18%|█▊        | 90/500 [00:26<02:00,  3.40it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 90: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  18%|█▊        | 91/500 [00:27<01:59,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 91: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  18%|█▊        | 92/500 [00:27<01:58,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 92: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  19%|█▊        | 93/500 [00:27<01:57,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 93: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  19%|█▉        | 94/500 [00:28<02:00,  3.38it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 94: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  19%|█▉        | 95/500 [00:28<01:58,  3.42it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 95: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  19%|█▉        | 96/500 [00:28<01:57,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 96: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  19%|█▉        | 97/500 [00:28<01:57,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 97: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  20%|█▉        | 98/500 [00:29<01:56,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 98: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  20%|█▉        | 99/500 [00:29<01:55,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 99: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  20%|██        | 100/500 [00:29<01:55,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 100: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  20%|██        | 101/500 [00:30<01:55,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 101: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  20%|██        | 102/500 [00:30<01:54,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 102: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  21%|██        | 103/500 [00:30<01:53,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 103: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  21%|██        | 104/500 [00:30<01:53,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 104: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  21%|██        | 105/500 [00:31<01:53,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 105: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  21%|██        | 106/500 [00:31<01:54,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 106: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  21%|██▏       | 107/500 [00:31<01:53,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 107: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  22%|██▏       | 108/500 [00:32<01:53,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 108: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  22%|██▏       | 109/500 [00:32<01:53,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 109: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  22%|██▏       | 110/500 [00:32<01:52,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 110: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  22%|██▏       | 111/500 [00:32<01:54,  3.40it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 111: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  22%|██▏       | 112/500 [00:33<01:53,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 112: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  23%|██▎       | 113/500 [00:33<01:52,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 113: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  23%|██▎       | 114/500 [00:33<01:51,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 114: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  23%|██▎       | 115/500 [00:34<01:50,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 115: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  23%|██▎       | 116/500 [00:34<01:49,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 116: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  23%|██▎       | 117/500 [00:34<01:49,  3.51it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 117: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  24%|██▎       | 118/500 [00:34<01:49,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 118: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  24%|██▍       | 119/500 [00:35<01:49,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 119: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  24%|██▍       | 120/500 [00:35<01:49,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 120: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  24%|██▍       | 121/500 [00:35<01:49,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 121: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  24%|██▍       | 122/500 [00:36<01:48,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 122: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  25%|██▍       | 123/500 [00:36<01:48,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 123: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  25%|██▍       | 124/500 [00:36<01:48,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 124: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  25%|██▌       | 125/500 [00:36<01:47,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 125: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  25%|██▌       | 126/500 [00:37<01:47,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 126: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  25%|██▌       | 127/500 [00:37<01:46,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 127: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  26%|██▌       | 128/500 [00:37<01:46,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 128: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  26%|██▌       | 129/500 [00:38<01:45,  3.51it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 129: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  26%|██▌       | 130/500 [00:38<01:45,  3.51it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 130: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  26%|██▌       | 131/500 [00:38<01:44,  3.52it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 131: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  26%|██▋       | 132/500 [00:38<01:45,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 132: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  27%|██▋       | 133/500 [00:39<01:44,  3.51it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 133: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  27%|██▋       | 134/500 [00:39<01:44,  3.51it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 134: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  27%|██▋       | 135/500 [00:39<01:44,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 135: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  27%|██▋       | 136/500 [00:40<01:44,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 136: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  27%|██▋       | 137/500 [00:40<01:44,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 137: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  28%|██▊       | 138/500 [00:40<01:44,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 138: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  28%|██▊       | 139/500 [00:40<01:44,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 139: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  28%|██▊       | 140/500 [00:41<01:43,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 140: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  28%|██▊       | 141/500 [00:41<01:42,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 141: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  28%|██▊       | 142/500 [00:41<01:42,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 142: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  29%|██▊       | 143/500 [00:42<01:42,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 143: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  29%|██▉       | 144/500 [00:42<01:42,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 144: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  29%|██▉       | 145/500 [00:42<01:42,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 145: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  29%|██▉       | 146/500 [00:43<01:44,  3.40it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 146: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  29%|██▉       | 147/500 [00:43<01:42,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 147: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  30%|██▉       | 148/500 [00:43<01:42,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 148: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  30%|██▉       | 149/500 [00:43<01:41,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 149: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  30%|███       | 150/500 [00:44<01:40,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 150: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  30%|███       | 151/500 [00:44<01:41,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 151: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  30%|███       | 152/500 [00:44<01:40,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 152: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  31%|███       | 153/500 [00:45<01:39,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 153: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  31%|███       | 154/500 [00:45<01:39,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 154: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  31%|███       | 155/500 [00:45<01:39,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 155: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  31%|███       | 156/500 [00:45<01:38,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 156: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  31%|███▏      | 157/500 [00:46<01:38,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 157: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  32%|███▏      | 158/500 [00:46<01:37,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 158: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  32%|███▏      | 159/500 [00:46<01:37,  3.51it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 159: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  32%|███▏      | 160/500 [00:47<01:36,  3.52it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 160: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  32%|███▏      | 161/500 [00:47<01:36,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 161: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  32%|███▏      | 162/500 [00:47<01:36,  3.51it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 162: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  33%|███▎      | 163/500 [00:47<01:38,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 163: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  33%|███▎      | 164/500 [00:48<01:38,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 164: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  33%|███▎      | 165/500 [00:48<01:36,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 165: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  33%|███▎      | 166/500 [00:48<01:35,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 166: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  33%|███▎      | 167/500 [00:49<01:35,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 167: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  34%|███▎      | 168/500 [00:49<01:34,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 168: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  34%|███▍      | 169/500 [00:49<01:34,  3.51it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 169: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  34%|███▍      | 170/500 [00:49<01:34,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 170: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  34%|███▍      | 171/500 [00:50<01:38,  3.35it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 171: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  34%|███▍      | 172/500 [00:50<01:36,  3.39it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 172: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  35%|███▍      | 173/500 [00:50<01:36,  3.40it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 173: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  35%|███▍      | 174/500 [00:51<01:34,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 174: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  35%|███▌      | 175/500 [00:51<01:33,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 175: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  35%|███▌      | 176/500 [00:51<01:35,  3.40it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 176: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  35%|███▌      | 177/500 [00:51<01:34,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 177: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  36%|███▌      | 178/500 [00:52<01:33,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 178: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  36%|███▌      | 179/500 [00:52<01:32,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 179: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  36%|███▌      | 180/500 [00:52<01:31,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 180: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  36%|███▌      | 181/500 [00:53<01:31,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 181: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  36%|███▋      | 182/500 [00:53<01:31,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 182: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  37%|███▋      | 183/500 [00:53<01:30,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 183: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  37%|███▋      | 184/500 [00:53<01:31,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 184: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  37%|███▋      | 185/500 [00:54<01:30,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 185: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  37%|███▋      | 186/500 [00:54<01:32,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 186: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  37%|███▋      | 187/500 [00:54<01:33,  3.35it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 187: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  38%|███▊      | 188/500 [00:55<01:32,  3.38it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 188: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  38%|███▊      | 189/500 [00:55<01:31,  3.39it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 189: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  38%|███▊      | 190/500 [00:55<01:30,  3.42it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 190: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  38%|███▊      | 191/500 [00:56<01:29,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 191: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  38%|███▊      | 192/500 [00:56<01:29,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 192: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  39%|███▊      | 193/500 [00:56<01:28,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 193: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  39%|███▉      | 194/500 [00:56<01:28,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 194: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  39%|███▉      | 195/500 [00:57<01:28,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 195: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  39%|███▉      | 196/500 [00:57<01:27,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 196: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  39%|███▉      | 197/500 [00:57<01:29,  3.40it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 197: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  40%|███▉      | 198/500 [00:58<01:28,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 198: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  40%|███▉      | 199/500 [00:58<01:27,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 199: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  40%|████      | 200/500 [00:58<01:26,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 200: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  40%|████      | 201/500 [00:58<01:26,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 201: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  40%|████      | 202/500 [00:59<01:25,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 202: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  41%|████      | 203/500 [00:59<01:25,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 203: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  41%|████      | 204/500 [00:59<01:24,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 204: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  41%|████      | 205/500 [01:00<01:24,  3.51it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 205: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  41%|████      | 206/500 [01:00<01:24,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 206: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  41%|████▏     | 207/500 [01:00<01:24,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 207: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  42%|████▏     | 208/500 [01:00<01:25,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 208: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  42%|████▏     | 209/500 [01:01<01:24,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 209: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  42%|████▏     | 210/500 [01:01<01:24,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 210: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  42%|████▏     | 211/500 [01:01<01:23,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 211: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  42%|████▏     | 212/500 [01:02<01:25,  3.39it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 212: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  43%|████▎     | 213/500 [01:02<01:24,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 213: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  43%|████▎     | 214/500 [01:02<01:25,  3.34it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 214: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  43%|████▎     | 215/500 [01:03<01:26,  3.30it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 215: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  43%|████▎     | 216/500 [01:03<01:24,  3.36it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 216: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  43%|████▎     | 217/500 [01:03<01:23,  3.40it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 217: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  44%|████▎     | 218/500 [01:03<01:22,  3.42it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 218: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  44%|████▍     | 219/500 [01:04<01:20,  3.51it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 219: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  44%|████▍     | 220/500 [01:04<01:19,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 220: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  44%|████▍     | 221/500 [01:04<01:19,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 221: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  44%|████▍     | 222/500 [01:05<01:19,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 222: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  45%|████▍     | 223/500 [01:05<01:19,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 223: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  45%|████▍     | 224/500 [01:05<01:19,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 224: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  45%|████▌     | 225/500 [01:05<01:18,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 225: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  45%|████▌     | 226/500 [01:06<01:18,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 226: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  45%|████▌     | 227/500 [01:06<01:20,  3.40it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 227: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  46%|████▌     | 228/500 [01:06<01:19,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 228: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  46%|████▌     | 229/500 [01:07<01:18,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 229: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  46%|████▌     | 230/500 [01:07<01:18,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 230: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  46%|████▌     | 231/500 [01:07<01:19,  3.38it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 231: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  46%|████▋     | 232/500 [01:08<01:22,  3.26it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 232: GPU Memory Used: 3.168 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  47%|████▋     | 233/500 [01:08<01:20,  3.33it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 233: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  47%|████▋     | 234/500 [01:08<01:18,  3.39it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 234: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  47%|████▋     | 235/500 [01:08<01:17,  3.42it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 235: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  47%|████▋     | 236/500 [01:09<01:16,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 236: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  47%|████▋     | 237/500 [01:09<01:16,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 237: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  48%|████▊     | 238/500 [01:09<01:15,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 238: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  48%|████▊     | 239/500 [01:10<01:16,  3.40it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 239: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  48%|████▊     | 240/500 [01:10<01:16,  3.42it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 240: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  48%|████▊     | 241/500 [01:10<01:15,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 241: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  48%|████▊     | 242/500 [01:10<01:14,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 242: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  49%|████▊     | 243/500 [01:11<01:14,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 243: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  49%|████▉     | 244/500 [01:11<01:13,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 244: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  49%|████▉     | 245/500 [01:11<01:13,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 245: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  49%|████▉     | 246/500 [01:12<01:13,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 246: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  49%|████▉     | 247/500 [01:12<01:12,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 247: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  50%|████▉     | 248/500 [01:12<01:12,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 248: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  50%|████▉     | 249/500 [01:12<01:12,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 249: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  50%|█████     | 250/500 [01:13<01:11,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 250: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  50%|█████     | 251/500 [01:13<01:11,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 251: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  50%|█████     | 252/500 [01:13<01:11,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 252: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  51%|█████     | 253/500 [01:14<01:10,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 253: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  51%|█████     | 254/500 [01:14<01:10,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 254: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  51%|█████     | 255/500 [01:14<01:10,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 255: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  51%|█████     | 256/500 [01:14<01:09,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 256: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  51%|█████▏    | 257/500 [01:15<01:09,  3.51it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 257: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  52%|█████▏    | 258/500 [01:15<01:10,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 258: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  52%|█████▏    | 259/500 [01:15<01:10,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 259: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  52%|█████▏    | 260/500 [01:16<01:09,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 260: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  52%|█████▏    | 261/500 [01:16<01:09,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 261: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  52%|█████▏    | 262/500 [01:16<01:08,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 262: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  53%|█████▎    | 263/500 [01:16<01:08,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 263: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  53%|█████▎    | 264/500 [01:17<01:07,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 264: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  53%|█████▎    | 265/500 [01:17<01:07,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 265: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  53%|█████▎    | 266/500 [01:17<01:06,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 266: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  53%|█████▎    | 267/500 [01:18<01:06,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 267: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  54%|█████▎    | 268/500 [01:18<01:06,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 268: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  54%|█████▍    | 269/500 [01:18<01:06,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 269: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  54%|█████▍    | 270/500 [01:18<01:09,  3.32it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 270: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  54%|█████▍    | 271/500 [01:19<01:08,  3.36it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 271: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  54%|█████▍    | 272/500 [01:19<01:06,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 272: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  55%|█████▍    | 273/500 [01:19<01:05,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 273: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  55%|█████▍    | 274/500 [01:20<01:05,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 274: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  55%|█████▌    | 275/500 [01:20<01:04,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 275: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  55%|█████▌    | 276/500 [01:20<01:04,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 276: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  55%|█████▌    | 277/500 [01:20<01:04,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 277: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  56%|█████▌    | 278/500 [01:21<01:03,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 278: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  56%|█████▌    | 279/500 [01:21<01:03,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 279: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  56%|█████▌    | 280/500 [01:21<01:03,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 280: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  56%|█████▌    | 281/500 [01:22<01:03,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 281: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  56%|█████▋    | 282/500 [01:22<01:02,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 282: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  57%|█████▋    | 283/500 [01:22<01:02,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 283: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  57%|█████▋    | 284/500 [01:22<01:02,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 284: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  57%|█████▋    | 285/500 [01:23<01:03,  3.40it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 285: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  57%|█████▋    | 286/500 [01:23<01:02,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 286: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  57%|█████▋    | 287/500 [01:23<01:01,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 287: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  58%|█████▊    | 288/500 [01:24<01:01,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 288: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  58%|█████▊    | 289/500 [01:24<01:00,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 289: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  58%|█████▊    | 290/500 [01:24<01:00,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 290: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  58%|█████▊    | 291/500 [01:25<01:01,  3.39it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 291: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  58%|█████▊    | 292/500 [01:25<01:02,  3.33it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 292: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  59%|█████▊    | 293/500 [01:25<01:01,  3.39it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 293: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  59%|█████▉    | 294/500 [01:25<01:00,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 294: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  59%|█████▉    | 295/500 [01:26<00:59,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 295: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  59%|█████▉    | 296/500 [01:26<00:58,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 296: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  59%|█████▉    | 297/500 [01:26<00:58,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 297: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  60%|█████▉    | 298/500 [01:27<00:58,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 298: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  60%|█████▉    | 299/500 [01:27<00:59,  3.38it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 299: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  60%|██████    | 300/500 [01:27<01:00,  3.33it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 300: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  60%|██████    | 301/500 [01:27<00:58,  3.37it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 301: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  60%|██████    | 302/500 [01:28<00:58,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 302: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  61%|██████    | 303/500 [01:28<00:57,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 303: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  61%|██████    | 304/500 [01:28<00:56,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 304: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  61%|██████    | 305/500 [01:29<00:56,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 305: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  61%|██████    | 306/500 [01:29<00:55,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 306: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  61%|██████▏   | 307/500 [01:29<00:55,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 307: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  62%|██████▏   | 308/500 [01:29<00:55,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 308: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  62%|██████▏   | 309/500 [01:30<00:54,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 309: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  62%|██████▏   | 310/500 [01:30<00:54,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 310: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  62%|██████▏   | 311/500 [01:30<00:55,  3.40it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 311: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  62%|██████▏   | 312/500 [01:31<00:55,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 312: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  63%|██████▎   | 313/500 [01:31<00:54,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 313: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  63%|██████▎   | 314/500 [01:31<00:53,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 314: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  63%|██████▎   | 315/500 [01:32<00:53,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 315: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  63%|██████▎   | 316/500 [01:32<00:53,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 316: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  63%|██████▎   | 317/500 [01:32<00:52,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 317: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  64%|██████▎   | 318/500 [01:32<00:52,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 318: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  64%|██████▍   | 319/500 [01:33<00:53,  3.39it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 319: GPU Memory Used: 3.152 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  64%|██████▍   | 320/500 [01:33<00:52,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 320: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  64%|██████▍   | 321/500 [01:33<00:53,  3.37it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 321: GPU Memory Used: 3.152 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  64%|██████▍   | 322/500 [01:34<00:52,  3.40it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 322: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  65%|██████▍   | 323/500 [01:34<00:51,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 323: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  65%|██████▍   | 324/500 [01:34<00:51,  3.39it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 324: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  65%|██████▌   | 325/500 [01:34<00:51,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 325: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  65%|██████▌   | 326/500 [01:35<00:51,  3.37it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 326: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  65%|██████▌   | 327/500 [01:35<00:50,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 327: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  66%|██████▌   | 328/500 [01:35<00:50,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 328: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  66%|██████▌   | 329/500 [01:36<00:49,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 329: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  66%|██████▌   | 330/500 [01:36<00:49,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 330: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  66%|██████▌   | 331/500 [01:36<00:48,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 331: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  66%|██████▋   | 332/500 [01:37<00:49,  3.40it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 332: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  67%|██████▋   | 333/500 [01:37<00:48,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 333: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  67%|██████▋   | 334/500 [01:37<00:48,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 334: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  67%|██████▋   | 335/500 [01:37<00:47,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 335: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  67%|██████▋   | 336/500 [01:38<00:47,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 336: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  67%|██████▋   | 337/500 [01:38<00:47,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 337: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  68%|██████▊   | 338/500 [01:38<00:46,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 338: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  68%|██████▊   | 339/500 [01:39<00:46,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 339: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  68%|██████▊   | 340/500 [01:39<00:46,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 340: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  68%|██████▊   | 341/500 [01:39<00:45,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 341: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  68%|██████▊   | 342/500 [01:39<00:45,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 342: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  69%|██████▊   | 343/500 [01:40<00:44,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 343: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  69%|██████▉   | 344/500 [01:40<00:45,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 344: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  69%|██████▉   | 345/500 [01:40<00:46,  3.36it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 345: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  69%|██████▉   | 346/500 [01:41<00:45,  3.39it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 346: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  69%|██████▉   | 347/500 [01:41<00:44,  3.42it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 347: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  70%|██████▉   | 348/500 [01:41<00:44,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 348: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  70%|██████▉   | 349/500 [01:41<00:43,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 349: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  70%|███████   | 350/500 [01:42<00:43,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 350: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  70%|███████   | 351/500 [01:42<00:42,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 351: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  70%|███████   | 352/500 [01:42<00:42,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 352: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  71%|███████   | 353/500 [01:43<00:42,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 353: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  71%|███████   | 354/500 [01:43<00:41,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 354: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  71%|███████   | 355/500 [01:43<00:41,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 355: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  71%|███████   | 356/500 [01:43<00:41,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 356: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  71%|███████▏  | 357/500 [01:44<00:41,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 357: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  72%|███████▏  | 358/500 [01:44<00:41,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 358: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  72%|███████▏  | 359/500 [01:44<00:40,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 359: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  72%|███████▏  | 360/500 [01:45<00:40,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 360: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  72%|███████▏  | 361/500 [01:45<00:40,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 361: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  72%|███████▏  | 362/500 [01:45<00:39,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 362: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  73%|███████▎  | 363/500 [01:45<00:39,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 363: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  73%|███████▎  | 364/500 [01:46<00:38,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 364: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  73%|███████▎  | 365/500 [01:46<00:39,  3.42it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 365: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  73%|███████▎  | 366/500 [01:46<00:38,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 366: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  73%|███████▎  | 367/500 [01:47<00:38,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 367: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  74%|███████▎  | 368/500 [01:47<00:37,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 368: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  74%|███████▍  | 369/500 [01:47<00:37,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 369: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  74%|███████▍  | 370/500 [01:47<00:37,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 370: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  74%|███████▍  | 371/500 [01:48<00:37,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 371: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  74%|███████▍  | 372/500 [01:48<00:36,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 372: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  75%|███████▍  | 373/500 [01:48<00:36,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 373: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  75%|███████▍  | 374/500 [01:49<00:36,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 374: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  75%|███████▌  | 375/500 [01:49<00:37,  3.35it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 375: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  75%|███████▌  | 376/500 [01:49<00:36,  3.40it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 376: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  75%|███████▌  | 377/500 [01:50<00:35,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 377: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  76%|███████▌  | 378/500 [01:50<00:35,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 378: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  76%|███████▌  | 379/500 [01:50<00:35,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 379: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  76%|███████▌  | 380/500 [01:50<00:34,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 380: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  76%|███████▌  | 381/500 [01:51<00:34,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 381: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  76%|███████▋  | 382/500 [01:51<00:33,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 382: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  77%|███████▋  | 383/500 [01:51<00:33,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 383: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  77%|███████▋  | 384/500 [01:52<00:33,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 384: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  77%|███████▋  | 385/500 [01:52<00:32,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 385: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  77%|███████▋  | 386/500 [01:52<00:32,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 386: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  77%|███████▋  | 387/500 [01:52<00:32,  3.51it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 387: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  78%|███████▊  | 388/500 [01:53<00:32,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 388: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  78%|███████▊  | 389/500 [01:53<00:32,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 389: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  78%|███████▊  | 390/500 [01:53<00:31,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 390: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  78%|███████▊  | 391/500 [01:54<00:31,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 391: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  78%|███████▊  | 392/500 [01:54<00:31,  3.39it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 392: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  79%|███████▊  | 393/500 [01:54<00:32,  3.33it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 393: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  79%|███████▉  | 394/500 [01:54<00:31,  3.37it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 394: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  79%|███████▉  | 395/500 [01:55<00:31,  3.34it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 395: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  79%|███████▉  | 396/500 [01:55<00:30,  3.37it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 396: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  79%|███████▉  | 397/500 [01:55<00:30,  3.34it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 397: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  80%|███████▉  | 398/500 [01:56<00:30,  3.39it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 398: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  80%|███████▉  | 399/500 [01:56<00:29,  3.42it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 399: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  80%|████████  | 400/500 [01:56<00:29,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 400: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  80%|████████  | 401/500 [01:56<00:28,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 401: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  80%|████████  | 402/500 [01:57<00:28,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 402: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  81%|████████  | 403/500 [01:57<00:28,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 403: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  81%|████████  | 404/500 [01:57<00:27,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 404: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  81%|████████  | 405/500 [01:58<00:27,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 405: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  81%|████████  | 406/500 [01:58<00:27,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 406: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  81%|████████▏ | 407/500 [01:58<00:26,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 407: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  82%|████████▏ | 408/500 [01:59<00:26,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 408: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  82%|████████▏ | 409/500 [01:59<00:26,  3.39it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 409: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  82%|████████▏ | 410/500 [01:59<00:26,  3.42it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 410: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  82%|████████▏ | 411/500 [01:59<00:25,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 411: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  82%|████████▏ | 412/500 [02:00<00:25,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 412: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  83%|████████▎ | 413/500 [02:00<00:25,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 413: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  83%|████████▎ | 414/500 [02:00<00:24,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 414: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  83%|████████▎ | 415/500 [02:01<00:24,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 415: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  83%|████████▎ | 416/500 [02:01<00:24,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 416: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  83%|████████▎ | 417/500 [02:01<00:24,  3.39it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 417: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  84%|████████▎ | 418/500 [02:01<00:23,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 418: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  84%|████████▍ | 419/500 [02:02<00:23,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 419: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  84%|████████▍ | 420/500 [02:02<00:23,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 420: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  84%|████████▍ | 421/500 [02:02<00:22,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 421: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  84%|████████▍ | 422/500 [02:03<00:22,  3.42it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 422: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  85%|████████▍ | 423/500 [02:03<00:22,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 423: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  85%|████████▍ | 424/500 [02:03<00:22,  3.36it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 424: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  85%|████████▌ | 425/500 [02:03<00:22,  3.40it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 425: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  85%|████████▌ | 426/500 [02:04<00:22,  3.35it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 426: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  85%|████████▌ | 427/500 [02:04<00:21,  3.39it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 427: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  86%|████████▌ | 428/500 [02:04<00:20,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 428: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  86%|████████▌ | 429/500 [02:05<00:21,  3.38it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 429: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  86%|████████▌ | 430/500 [02:05<00:20,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 430: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  86%|████████▌ | 431/500 [02:05<00:20,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 431: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  86%|████████▋ | 432/500 [02:06<00:20,  3.35it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 432: GPU Memory Used: 3.152 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  87%|████████▋ | 433/500 [02:06<00:19,  3.37it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 433: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  87%|████████▋ | 434/500 [02:06<00:19,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 434: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  87%|████████▋ | 435/500 [02:06<00:19,  3.37it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 435: GPU Memory Used: 3.152 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  87%|████████▋ | 436/500 [02:07<00:19,  3.31it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 436: GPU Memory Used: 3.152 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  87%|████████▋ | 437/500 [02:07<00:19,  3.29it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 437: GPU Memory Used: 3.152 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  88%|████████▊ | 438/500 [02:07<00:18,  3.35it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 438: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  88%|████████▊ | 439/500 [02:08<00:18,  3.32it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 439: GPU Memory Used: 3.152 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  88%|████████▊ | 440/500 [02:08<00:17,  3.36it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 440: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  88%|████████▊ | 441/500 [02:08<00:17,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 441: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  88%|████████▊ | 442/500 [02:08<00:16,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 442: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  89%|████████▊ | 443/500 [02:09<00:16,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 443: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  89%|████████▉ | 444/500 [02:09<00:16,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 444: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  89%|████████▉ | 445/500 [02:09<00:15,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 445: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  89%|████████▉ | 446/500 [02:10<00:15,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 446: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  89%|████████▉ | 447/500 [02:10<00:15,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 447: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  90%|████████▉ | 448/500 [02:10<00:14,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 448: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  90%|████████▉ | 449/500 [02:11<00:14,  3.42it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 449: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  90%|█████████ | 450/500 [02:11<00:14,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 450: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  90%|█████████ | 451/500 [02:11<00:14,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 451: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  90%|█████████ | 452/500 [02:11<00:13,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 452: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  91%|█████████ | 453/500 [02:12<00:13,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 453: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  91%|█████████ | 454/500 [02:12<00:13,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 454: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  91%|█████████ | 455/500 [02:12<00:13,  3.40it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 455: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  91%|█████████ | 456/500 [02:13<00:13,  3.36it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 456: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  91%|█████████▏| 457/500 [02:13<00:12,  3.40it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 457: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  92%|█████████▏| 458/500 [02:13<00:12,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 458: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  92%|█████████▏| 459/500 [02:13<00:12,  3.35it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 459: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  92%|█████████▏| 460/500 [02:14<00:11,  3.38it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 460: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  92%|█████████▏| 461/500 [02:14<00:11,  3.42it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 461: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  92%|█████████▏| 462/500 [02:14<00:11,  3.37it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 462: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  93%|█████████▎| 463/500 [02:15<00:11,  3.31it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 463: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  93%|█████████▎| 464/500 [02:15<00:10,  3.36it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 464: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  93%|█████████▎| 465/500 [02:15<00:10,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 465: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  93%|█████████▎| 466/500 [02:16<00:09,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 466: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  93%|█████████▎| 467/500 [02:16<00:09,  3.37it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 467: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  94%|█████████▎| 468/500 [02:16<00:09,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 468: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  94%|█████████▍| 469/500 [02:16<00:09,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 469: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  94%|█████████▍| 470/500 [02:17<00:08,  3.38it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 470: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  94%|█████████▍| 471/500 [02:17<00:08,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 471: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  94%|█████████▍| 472/500 [02:17<00:08,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 472: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  95%|█████████▍| 473/500 [02:18<00:07,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 473: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  95%|█████████▍| 474/500 [02:18<00:07,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 474: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  95%|█████████▌| 475/500 [02:18<00:07,  3.41it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 475: GPU Memory Used: 3.152 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  95%|█████████▌| 476/500 [02:18<00:06,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 476: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  95%|█████████▌| 477/500 [02:19<00:06,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 477: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  96%|█████████▌| 478/500 [02:19<00:06,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 478: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  96%|█████████▌| 479/500 [02:19<00:06,  3.48it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 479: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  96%|█████████▌| 480/500 [02:20<00:05,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 480: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  96%|█████████▌| 481/500 [02:20<00:05,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 481: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  96%|█████████▋| 482/500 [02:20<00:05,  3.51it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 482: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  97%|█████████▋| 483/500 [02:20<00:04,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 483: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  97%|█████████▋| 484/500 [02:21<00:04,  3.43it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 484: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  97%|█████████▋| 485/500 [02:21<00:04,  3.44it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 485: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  97%|█████████▋| 486/500 [02:21<00:04,  3.45it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 486: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  97%|█████████▋| 487/500 [02:22<00:03,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 487: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  98%|█████████▊| 488/500 [02:22<00:03,  3.46it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 488: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  98%|█████████▊| 489/500 [02:22<00:03,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 489: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  98%|█████████▊| 490/500 [02:22<00:02,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 490: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  98%|█████████▊| 491/500 [02:23<00:02,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 491: GPU Memory Used: 3.148 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  98%|█████████▊| 492/500 [02:23<00:02,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 492: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  99%|█████████▊| 493/500 [02:23<00:02,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 493: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  99%|█████████▉| 494/500 [02:24<00:01,  3.47it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 494: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  99%|█████████▉| 495/500 [02:24<00:01,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 495: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  99%|█████████▉| 496/500 [02:24<00:01,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 496: GPU Memory Used: 3.145 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  99%|█████████▉| 497/500 [02:24<00:00,  3.49it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 497: GPU Memory Used: 3.146 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|█████████▉| 498/500 [02:25<00:00,  3.50it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 498: GPU Memory Used: 3.143 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|█████████▉| 499/500 [02:25<00:00,  3.42it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Sample 499: GPU Memory Used: 3.150 GB\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]","output_type":"stream"},{"name":"stdout","text":"Sample 500: GPU Memory Used: 3.148 GB\nAvg latency: 0.079 sec\nTokens per sec: 13.05\nAvg perplexity: nan\nBLEU Score: 0.000\nROUGE-1 Score: 0.000\nROUGE-L Score: 0.000\nMemory usage (GB): 3.146\nFLOP Reduction (%): 0.00\nRetrieval Latency (sec): 0.000\nF1 Score: 0.000\nKnowledge Retention: 0.000\nMemory Reduction (%): 0.00\nQuery Processing Time (sec): 0.079\nAccuracy Drop: 0.000\nCompression Ratio: 1.00\n","output_type":"stream"},{"name":"stderr","text":"\n/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n  return _methods._mean(a, axis=axis, dtype=dtype,\n/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n  ret = ret.dtype.type(ret / rcount)\n","output_type":"stream"}],"execution_count":1}]}